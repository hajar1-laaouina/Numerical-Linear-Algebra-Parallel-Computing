# -*- coding: utf-8 -*-
"""pagerank assignment hajar laaouina.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yfr5Fv8jyYMzMz_aP_aDTYOBRpIvjcp1
"""

import networkx as nx
import matplotlib.pyplot as plt
from scipy.sparse import coo_matrix
from scipy.sparse import csr_matrix

# Read the graph data from file and create a directed graph
data = []
with open('data.txt', 'r') as f:
    for line in f:
        if line.startswith('#'):
            continue
        parts = line.strip().split()
        if len(parts) != 2:
            continue
        data.append((int(parts[0]), int(parts[1])))
graph = nx.DiGraph(data)

n_nodes = max(max(pair) for pair in data)
row = [pair[0]-1 for pair in data]  
col = [pair[1]-1 for pair in data]  
adjacency_matrix = csr_matrix(([1]*len(data), (row, col)), shape=(n_nodes, n_nodes))

# Calculate PageRank scores and print top nodes
pagerank_scores = nx.pagerank(graph)
top_nodes = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:10]
for node, score in top_nodes:
    print(f"Node: {node}, Score: {score:.6f}")

# Print top 100 nodes and their scores
sorted_nodes = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:100]
for node, score in sorted_nodes:
    print(f"Node: {node}, Score: {score:.6f}")

# Plot histogram of PageRank scores for top 100 nodes
scores = [score for node, score in sorted_nodes]
plt.hist(scores, bins=20)
plt.xlabel('PageRank score')
plt.ylabel('Frequency')
plt.title('Distribution of PageRank scores for top 100 nodes')
plt.show()

